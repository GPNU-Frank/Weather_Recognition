{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd04905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化 对比度 饱和度等特征\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    return (data - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集\n",
    "train_root_path = \"G:\\\\vscode_workspace\\\\Weather_Recognition\\\\data_split_v6\\\\train\\\\\"\n",
    "train_x = []\n",
    "train_y = []\n",
    "label_dict = {'Cloud': 0, 'Sunny': 1}\n",
    "if not os.path.exists(train_root_path):\n",
    "    print(train_root_path)\n",
    "    raise FileNotFoundError\n",
    "with os.scandir(train_root_path) as root:\n",
    "    for emotion in root:\n",
    "        if emotion.name not in label_dict:\n",
    "            continue\n",
    "        label = label_dict[emotion.name]\n",
    "        with os.scandir(emotion.path) as fold:\n",
    "            for img in fold:\n",
    "                img = cv2.imread(img.path)\n",
    "                img = cv2.resize(img, (480, 480))\n",
    "                img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "                hist_s = cv2.calcHist([img_hsv], [1], None, [256], [0.0, 255.0])\n",
    "                standardization(hist_s)\n",
    "                hist_l = cv2.calcHist([img_lab], [0], None, [256], [0.0, 255.0])\n",
    "                standardization(hist_l)\n",
    "                train_x.append(np.concatenate((hist_s, hist_l), axis=0))\n",
    "                train_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载测试集\n",
    "test_root_path = \"G:\\\\vscode_workspace\\\\Weather_Recognition\\\\data_split_v6\\\\test\\\\\"\n",
    "test_x = []\n",
    "test_y = []\n",
    "label_dict = {'Cloud': 0, 'Sunny': 1}\n",
    "if not os.path.exists(test_root_path):\n",
    "    print(test_root_path)\n",
    "    raise FileNotFoundError\n",
    "with os.scandir(test_root_path) as root:\n",
    "    for emotion in root:\n",
    "        if emotion.name not in label_dict:\n",
    "            continue\n",
    "        label = label_dict[emotion.name]\n",
    "        with os.scandir(emotion.path) as fold:\n",
    "            for img in fold:\n",
    "                img = cv2.imread(img.path)\n",
    "                img = cv2.resize(img, (480, 480))\n",
    "                img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "                hist_s = cv2.calcHist([img_hsv], [1], None, [256], [0.0, 255.0])\n",
    "                hist_l = cv2.calcHist([img_lab], [0], None, [256], [0.0, 255.0])\n",
    "                standardization(hist_s)\n",
    "                standardization(hist_l)\n",
    "                test_x.append(np.concatenate((hist_s, hist_l), axis=0))\n",
    "                test_y.append(label)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "test_x = test_x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15570 15570\n(15570, 512, 1)\n(15570,)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x), len(train_y))\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15570, 512)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x.squeeze()\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4470, 512) (4470,)\n"
     ]
    }
   ],
   "source": [
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=300)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "AB = AdaBoostClassifier(n_estimators=300)\n",
    "AB.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "import pickle\n",
    "save_path = \"adaboost_s_l_norm_densenet121_300.pkl\"\n",
    "with open(save_path, 'wb') as pfile:\n",
    "    pickle.dump(AB, pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5681818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# train_acc_svc = accuracy_score(AB.predict(train_x), train_y)\n",
    "# test_acc_svc = accuracy_score(AB.predict(test_x), test_y)\n",
    "val_acc_svc = accuracy_score(AB.predict(val_x), val_y)\n",
    "# print(train_acc_svc)\n",
    "# print(test_acc_svc)\n",
    "print(val_acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载公司测试集\n",
    "val_root_path = \"G:\\\\vscode_workspace\\\\Weather_Recognition\\\\val_imgs_2\\\\\"\n",
    "val_x = []\n",
    "val_y = []\n",
    "label_dict = {'Cloud': 0, 'Sunny': 1}\n",
    "if not os.path.exists(val_root_path):\n",
    "    print(val_root_path)\n",
    "    raise FileNotFoundError\n",
    "with os.scandir(val_root_path) as root:\n",
    "    for emotion in root:\n",
    "        if emotion.name not in label_dict:\n",
    "            continue\n",
    "        label = label_dict[emotion.name]\n",
    "        with os.scandir(emotion.path) as fold:\n",
    "            for img in fold:\n",
    "                img = cv2.imread(img.path)\n",
    "                img = cv2.resize(img, (480, 480))\n",
    "                img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "                img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "                hist_s = cv2.calcHist([img_hsv], [1], None, [256], [0.0, 255.0])\n",
    "                hist_l = cv2.calcHist([img_lab], [0], None, [256], [0.0, 255.0])\n",
    "                standardization(hist_s)\n",
    "                standardization(hist_l)\n",
    "                val_x.append(np.concatenate((hist_s, hist_l), axis=0))\n",
    "                val_y.append(label)\n",
    "val_x = np.array(val_x)\n",
    "val_y = np.array(val_y)\n",
    "val_x = val_x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_train_sl_512_densenet121_1024.pkl', 'rb') as f:\n",
    "    my_dict = pickle.load(f)\n",
    "\n",
    "# my_dict = {'sl_features': sl_features, 'features_blobs': features_blobs, 'labels': label}\n",
    "sl_features = my_dict['sl_features']\n",
    "features_blobs = my_dict['features_blobs']\n",
    "label = my_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15570, 1536) (15570,)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.concatenate((sl_features, features_blobs), axis=1)\n",
    "train_y = label\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4470, 1536) (4470,)\n"
     ]
    }
   ],
   "source": [
    "with open('data_test_sl_512_densenet121_1024.pkl', 'rb') as f:\n",
    "    my_dict = pickle.load(f)\n",
    "\n",
    "# my_dict = {'sl_features': sl_features, 'features_blobs': features_blobs, 'labels': label}\n",
    "sl_features = my_dict['sl_features']\n",
    "features_blobs = my_dict['features_blobs']\n",
    "label = my_dict['labels']\n",
    "\n",
    "test_x = np.concatenate((sl_features, features_blobs), axis=1)\n",
    "test_y = label\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(440, 1536) (440,)\n"
     ]
    }
   ],
   "source": [
    "with open('data_val_sl_512_densenet121_1024.pkl', 'rb') as f:\n",
    "    my_dict = pickle.load(f)\n",
    "\n",
    "# my_dict = {'sl_features': sl_features, 'features_blobs': features_blobs, 'labels': label}\n",
    "sl_features = my_dict['sl_features']\n",
    "features_blobs = my_dict['features_blobs']\n",
    "label = my_dict['labels']\n",
    "\n",
    "val_x = np.concatenate((sl_features, features_blobs), axis=1)\n",
    "val_y = label\n",
    "print(val_x.shape, val_y.shape)"
   ]
  }
 ]
}
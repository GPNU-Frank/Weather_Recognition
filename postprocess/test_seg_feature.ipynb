{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from models import resnet50, densenet_121, resnet50_adv, resnet18, resnet18_seg\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "checkpoint_path = '../checkpoints/my_data_v4_resnet18_seg_transfer_4class/01_20_23_34_fold_0_model_best.pth.tar'\n",
    "model = resnet18_seg()\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_dir = \"G:\\\\vscode_workspace\\\\Weather_Recognition\\\\data_split_v4\\\\train\\\\Cloud\"\n",
    "snow_dir = \"G:\\\\vscode_workspace\\\\Weather_Recognition\\\\data_split_v4\\\\snow_svm\\\\Snow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MyDataSegSnow, MyDataSegSnowSVM\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (576, 720)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((image_size, image_size)),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "dataset = MyDataSegSnowSVM(root_path=\"G:\\\\vscode_workspace\\\\Weather_Recognition\\\\data_split_v4\\\\train\\\\\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最后路面全连接层的特征\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output): # input是注册层的输入 output是注册层的输出\n",
    "    # print(\"hook input\",input[0].shape)\n",
    "    # features_blobs.append(output)\n",
    "    features_blobs.append(output.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x29535fb0580>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "features_blobs = []\n",
    "# model.model_h.st_gcn_networks[2].sigmoid.register_forward_hook(hook_feature)\n",
    "model.seg_avgpool.register_forward_hook(hook_feature)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 256, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "features_blobs = []\n",
    "features_labels = []\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "data_iter = torch.utils.data.DataLoader(dataset, 4, shuffle=True)\n",
    "for batch_idx, (inputs, inputs_seg, targets) in enumerate(data_iter):\n",
    "    inputs, inputs_seg, targets = inputs.cuda(), inputs_seg.cuda(), targets.cuda()\n",
    "    # inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    outputs = model(inputs, inputs_seg)\n",
    "    features_labels.append(targets.data.cpu().numpy())\n",
    "    # if batch_idx == 1:\n",
    "    #     break\n",
    "    # outputs = model(inputs)\n",
    "print(features_blobs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(12950, 256, 1, 1)\n(12950, 256)\n(12950,)\n"
     ]
    }
   ],
   "source": [
    "features_x = np.concatenate(features_blobs, axis=0)\n",
    "print(features_x.shape)\n",
    "features_x = features_x.reshape(-1, 256)\n",
    "print(features_x.shape)\n",
    "features_y = np.concatenate(features_labels, axis=0)\n",
    "print(features_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.996061776061776\n"
     ]
    }
   ],
   "source": [
    "# 支持向量机预测\n",
    "svc = SVC()\n",
    "svc.fit(features_x, features_y)\n",
    "# y_pred = svc.predict(x_test)\n",
    "svc.score(features_x, features_y)\n",
    "train_acc_svc = accuracy_score(svc.predict(features_x), features_y)\n",
    "# test_acc_svc = accuracy_score(svc.predict(x_test), y_test)\n",
    "print(train_acc_svc)\n",
    "# svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "import pickle\n",
    "save_path = \"snow_svm.pkl\"\n",
    "with open(save_path, 'wb') as pfile:\n",
    "    pickle.dump(svc, pfile)\n",
    "# joblib.dump(svc, 'snow_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.996061776061776\n"
     ]
    }
   ],
   "source": [
    "with open(\"snow_svm.pkl\", \"rb\") as f:\n",
    "    svc2 = pickle.load(f)\n",
    "train_acc_svc = accuracy_score(svc2.predict(features_x), features_y)\n",
    "# test_acc_svc = accuracy_score(svc.predict(x_test), y_test)\n",
    "print(train_acc_svc)"
   ]
  }
 ]
}